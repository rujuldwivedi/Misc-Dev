# -*- coding: utf-8 -*-
"""HSS422_TermPaper_GARCH_Granger_Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DFl5ShIQRX55duwstM0y3wZIWpmOGqYz

###GARCH
"""

import pandas as pd

# Create the dataset for NIFTY 50 and GDP
nifty_data = {
    "Year": [2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016],
    "Q1": [-4.16, 0.78, 5.19, -31.31, 7.05, -3.74, 11.62, -1.69],
    "Q2": [10.19, -9.95, 6.98, 19.37, 1.44, 5.96, 3.79, 6.95],
    "Q3": [2.41, 8.48, 11.72, 9.1, -2.45, 2.42, 2.96, 3.95],
    "Q4": [10.62, 6.03, -1.34, 22.71, 5.94, -0.39, 7.51, -4.95]
}

gdp_data = {
    "Year": [2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016],
    "Q1": [6858115, 6302446.53, 5448542.27, 5130411.6, 4872998.34, 4339193.52, 3875006.7, 3476632.47],
    "Q2": [7123165, 6523591, 5757109.45, 5140336.68, 4801283.99, 4584686, 4122770.68, 3695813.63],
    "Q3": [7049594, 6499562, 5126789.26, 3873443.4, 4942455.14, 4569369.11, 4008915.96, 3639774.61],
    "Q4": [7090221, 6468804, 5620166.01, 4721818.87, 4861652.38, 4656017.01, 4157246.35, 3754117.03]
}

# Convert to DataFrames
nifty_df = pd.DataFrame(nifty_data)
gdp_df = pd.DataFrame(gdp_data)

# Melt the data into long format
nifty_long = nifty_df.melt(id_vars="Year", var_name="Quarter", value_name="Nifty_50")
gdp_long = gdp_df.melt(id_vars="Year", var_name="Quarter", value_name="GDP_Price")

# Merge the data
data = pd.merge(nifty_long, gdp_long, on=["Year", "Quarter"])

# Create a datetime column from Year and Quarter
quarter_to_month = {"Q1": 1, "Q2": 4, "Q3": 7, "Q4": 10}
data["Month"] = data["Quarter"].map(quarter_to_month)
data["Date"] = pd.to_datetime(data["Year"].astype(str) + "-" + data["Month"].astype(str) + "-01")
data.set_index("Date", inplace=True)
data.sort_index(inplace=True)

# Calculate returns (percentage changes)
data["Nifty_Returns"] = data["Nifty_50"]  # Nifty 50 data already in percentage change
data["GDP_Returns"] = 100 * data["GDP_Price"].pct_change()

# Display the transformed dataset
print(data.head())

# Plot the data (Optional)
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(data.index, data["Nifty_Returns"], label="Nifty 50 Returns", marker="o")
plt.plot(data.index, data["GDP_Returns"], label="GDP Returns", marker="x")
plt.title("Nifty 50 and GDP Returns Over Time", fontsize=16)
plt.xlabel("Date", fontsize=12)
plt.ylabel("Returns (%)", fontsize=12)
plt.legend(fontsize=12)
plt.grid()
plt.show()

!pip install arch

!pip install numpy
import numpy as np

from arch import arch_model
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
# Split into pre-COVID and post-COVID periods
pre_covid = data.loc['2015-01-01':'2020-03-31']
post_covid = data.loc['2020-04-01':]

# Visualize data
plt.figure(figsize=(10, 5))
plt.plot(data['Nifty_Returns'], label='Nifty 50 Returns')
plt.plot(data['GDP_Returns'], label='GDP Price Returns')
plt.legend()
plt.title('Returns: Nifty 50 vs GDP Price')
plt.show()

# GARCH Modeling
def fit_garch_model(returns, period_name):
    # ACF and PACF
    plot_acf(returns**2, title=f'ACF of Squared Returns ({period_name})')
    plt.show()

    # Fit GARCH(1,1)
    model = arch_model(returns, vol='Garch', p=1, q=1)
    model_fit = model.fit(disp='off')
    print(f'\nGARCH(1,1) Summary for {period_name}:\n', model_fit.summary())
    return model_fit

print("Pre-COVID Analysis")
pre_covid_garch = fit_garch_model(pre_covid['Nifty_Returns'].dropna(), "Pre-COVID")

print("\nPost-COVID Analysis")
post_covid_garch = fit_garch_model(post_covid['Nifty_Returns'].dropna(), "Post-COVID")

# Rolling Forecasts
def rolling_forecast(returns, garch_model, test_size=100):
    rolling_predictions = []
    for i in range(test_size):
        train = returns[:-(test_size - i)]
        model = arch_model(train, vol='Garch', p=1, q=1)
        model_fit = model.fit(disp='off')
        pred = model_fit.forecast(horizon=1)
        rolling_predictions.append(np.sqrt(pred.variance.values[-1, :][0]))
    return rolling_predictions

test_size = int(len(post_covid) * 0.2)  # 20% as test data
rolling_preds_post = rolling_forecast(post_covid['Nifty_Returns'].dropna(), post_covid_garch, test_size)

plt.figure(figsize=(10, 5))
plt.plot(post_covid['Nifty_Returns'][-test_size:], label='True Returns')
plt.plot(rolling_preds_post, label='Predicted Volatility', color='red')
plt.legend()
plt.title('Post-COVID Rolling Volatility Forecast')
plt.show()

"""###Regression"""

import pandas as pd
import numpy as np
import statsmodels.api as sm
import matplotlib.pyplot as plt

# Create DataFrames
gdp_data = {
    "Year": [2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016],
    "Q1": [6858115, 6302446.53, 5448542.27, 5130411.6, 4872998.34, 4339193.52, 3875006.7, 3476632.47],
    "Q2": [7123165, 6523591, 5757109.45, 5140336.68, 4801283.99, 4584686, 4122770.68, 3695813.63],
    "Q3": [7049594, 6499562, 5126789.26, 3873443.4, 4942455.14, 4569369.11, 4008915.96, 3639774.61],
    "Q4": [7090221, 6468804, 5620166.01, 4721818.87, 4861652.38, 4656017.01, 4157246.35, 3754117.03]
}

nifty_data = {
    "Year": [2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016],
    "Q1": [-4.16, 0.78, 5.19, -31.31, 7.05, -3.74, 11.62, -1.69],
    "Q2": [10.19, -9.95, 6.98, 19.37, 1.44, 5.96, 3.79, 6.95],
    "Q3": [2.41, 8.48, 11.72, 9.1, -2.45, 2.42, 2.96, 3.95],
    "Q4": [10.62, 6.03, -1.34, 22.71, 5.94, -0.39, 7.51, -4.95]
}

# Convert dictionaries to DataFrames
gdp_df = pd.DataFrame(gdp_data).melt(id_vars="Year", var_name="Quarter", value_name="GDP")
nifty_df = pd.DataFrame(nifty_data).melt(id_vars="Year", var_name="Quarter", value_name="Nifty")

# Merge the data
combined_df = pd.merge(gdp_df, nifty_df, on=["Year", "Quarter"])
combined_df['Quarter_Num'] = combined_df['Quarter'].str.extract('(\d)').astype(int)
combined_df = combined_df.sort_values(by=["Year", "Quarter_Num"]).reset_index(drop=True)

# Calculate GDP Growth Rate
combined_df['GDP_Growth'] = combined_df['GDP'].pct_change() * 100
combined_df.dropna(inplace=True)  # Drop rows with NaN growth rates

# Regression Analysis
X = combined_df[['Nifty']]  # Independent variable
y = combined_df['GDP_Growth']  # Dependent variable

X = sm.add_constant(X)  # Add a constant for the intercept
model = sm.OLS(y, X).fit()

# Display results
print(model.summary())

# Plot the results
plt.scatter(combined_df['Nifty'], combined_df['GDP_Growth'], color='blue', label="Data")
plt.plot(combined_df['Nifty'], model.predict(X), color='red', label="Fitted Line")
plt.xlabel("Nifty Change (%)")
plt.ylabel("GDP Growth (%)")
plt.title("Regression Analysis: Nifty vs GDP Growth")
plt.legend()
plt.show()

"""###GRANGER CAUSALITY

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import grangercausalitytests

# Step 1: Load the data
gdp_data = {
    "Year": [2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016],
    "Q1": [6858115, 6302446.53, 5448542.27, 5130411.6, 4872998.34, 4339193.52, 3875006.7, 3476632.47],
    "Q2": [7123165, 6523591, 5757109.45, 5140336.68, 4801283.99, 4584686, 4122770.68, 3695813.63],
    "Q3": [7049594, 6499562, 5126789.26, 3873443.4, 4942455.14, 4569369.11, 4008915.96, 3639774.61],
    "Q4": [7090221, 6468804, 5620166.01, 4721818.87, 4861652.38, 4656017.01, 4157246.35, 3754117.03]
}
nifty_data = {
    "Year": [2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016],
    "Q1": [-4.16, 0.78, 5.19, -31.31, 7.05, -3.74, 11.62, -1.69],
    "Q2": [10.19, -9.95, 6.98, 19.37, 1.44, 5.96, 3.79, 6.95],
    "Q3": [2.41, 8.48, 11.72, 9.1, -2.45, 2.42, 2.96, 3.95],
    "Q4": [10.62, 6.03, -1.34, 22.71, 5.94, -0.39, 7.51, -4.95]
}

# Convert to DataFrame
gdp_df = pd.DataFrame(gdp_data)
nifty_df = pd.DataFrame(nifty_data)

# Step 2: Reshape data to long format
gdp_long = gdp_df.melt(id_vars=["Year"], var_name="Quarter", value_name="GDP")
nifty_long = nifty_df.melt(id_vars=["Year"], var_name="Quarter", value_name="NIFTY")

# Merge the datasets
combined_df = pd.merge(gdp_long, nifty_long, on=["Year", "Quarter"])
combined_df["Time"] = combined_df["Year"].astype(str) + combined_df["Quarter"]
combined_df = combined_df.sort_values("Time").reset_index(drop=True)

# Step 3: Prepare for Granger causality test
combined_df["GDP_diff"] = combined_df["GDP"].pct_change() * 100  # Calculate percentage change
combined_df["NIFTY_diff"] = combined_df["NIFTY"].pct_change()

# Drop NA values
granger_data = combined_df[["GDP_diff", "NIFTY_diff"]].dropna()

# Step 4: Perform Granger causality test
print("Granger Causality Test Results:")
granger_results = grangercausalitytests(granger_data, maxlag=3, verbose=True)

# Step 5: Plot the time series
plt.figure(figsize=(12, 6))
plt.plot(combined_df["Time"], combined_df["GDP_diff"], label="GDP Change (%)", color='blue')
plt.plot(combined_df["Time"], combined_df["NIFTY_diff"], label="NIFTY Change", color='red')
plt.xticks(rotation=45)
plt.legend()
plt.title("GDP vs NIFTY Percentage Change")
plt.show()

